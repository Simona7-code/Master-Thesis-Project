{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a866839c-3a64-4576-8bd1-c6b8640b06d6",
   "metadata": {},
   "source": [
    "# BERT Probing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3372ffdb-08ad-493d-8f85-258e77ee00c3",
   "metadata": {},
   "source": [
    "Il processo implementato segue la metodologia illustrata dal dottor Alessio Miaschi nel seguente repository: https://github.com/gsarti/lcl23-xnlm-lab/blob/main/notebooks/1.2_Probing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660755d0-487a-4287-8b0f-50d44bd51c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifica il percorso della cartella dove è presente il set \n",
    "sentences_file = \"/content/drive/My Drive/TMAG_Probing_Cita/dfs_post-cleaning/UD_15000records/Italian_UD.tsv\"\n",
    "# Lettura del DataFrame da un file TSV\n",
    "df = pd.read_csv(sentences_file, sep='\\t', quoting=3)\n",
    "\n",
    "# Specifica il percorso della cartella dove è presente il modello finetunato\n",
    "model_folder_path = \"/content/drive/My Drive/TMAG_Probing_Cita/FT_Models/lenght150/FTmode_2ep_set3_best\"\n",
    "##### VARIAZIONE IN PROBING SU MODELLO PRETRAINED\n",
    "##### model_name = \"dbmdz/bert-base-italian-xxl-uncased\"\n",
    "\n",
    "# Carica il tokenizer \n",
    "tokenizer = BertTokenizer.from_pretrained(model_folder_path)\n",
    "##### VARIAZIONE IN PROBING SU MODELLO PRETRAINED\n",
    "##### tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Carica il modello\n",
    "model = BertForSequenceClassification.from_pretrained(model_folder_path, output_hidden_states=True)\n",
    "##### VARIAZIONE IN PROBING SU MODELLO PRETRAINED\n",
    "##### model = AutoModel.from_pretrained(model_name, output_hidden_states=True)\n",
    "\n",
    "# Trasferisce il modello sulla GPU se disponibile, altrimenti rimane su CPU\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "\n",
    "# Liste vuote per memorizzare gli embedding, gli ID e le frasi\n",
    "embeddings = []\n",
    "ids = []\n",
    "sentences = []\n",
    "\n",
    "# Apertura del file contenente le frasi da elaborare\n",
    "with open(sentences_file, 'r') as f:\n",
    "    \n",
    "    # Iterazione attraverso ciascuna riga nel file\n",
    "    for line in f:\n",
    "        # Lista per memorizzare le rappresentazioni della frase corrente\n",
    "        embFrase=[]\n",
    "        # Estrazione degli elementi dalla riga separati da tabulazioni\n",
    "        elements = line.rstrip('\\n').split('\\t')\n",
    "        sent_id = elements[0]\n",
    "        sentence = elements[1]\n",
    "        # Tokenizzazione della frase utilizzando il tokenizer\n",
    "        input_ids = tokenizer.encode(sentence, add_special_tokens=True)\n",
    "        input_ids = torch.tensor([input_ids]).to(device)\n",
    "\n",
    "        # Estrazione delle rappresentazioni \n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids)\n",
    "            # Estrazione delle rappresentazioni dal primo layer\n",
    "            rappresentazione_layer6 = torch.squeeze(outputs['hidden_states'][1][:, 0, :])\n",
    "            # Estrazione delle rappresentazioni dall'ultimo layer\n",
    "            rappresentazione_layer12 = torch.squeeze(outputs['hidden_states'][-1][:,0,:])\n",
    "            # Crea una lista contenente i tensori dei layer 6 e 12\n",
    "            embFrase = [rappresentazione_layer6, rappresentazione_layer12]\n",
    "            embeddings.append(embFrase)\n",
    "            # Aggiunta dell'ID e della frase alle rispettive liste\n",
    "            ids.append(sent_id)\n",
    "            sentences.append(sentence)\n",
    "\n",
    "# Salvataggio delle rappresentazioni\n",
    "#with open(\"/content/drive/My Drive/TMAG_Probing_Cita/Bert_Representations/lenght150/Finetuned/ ItalianUD_Representations150_pt.pkl\", \"wb\") as fOut:\n",
    "  #pickle.dump({'ids': ids, 'sentences': sentences, 'embeddings': embeddings}, fOut)\n",
    "##### VARIAZIONE IN PROBING SU MODELLO PRETRAINED:\n",
    "#with open(\"/content/drive/My Drive/TMAG_Probing_Cita/Bert_Representations/lenght150/Pretrained/ ItalianUD_Representations150_pt.pkl\", \"wb\") as fOut:\n",
    "  #pickle.dump({'ids': ids, 'sentences': sentences, 'embeddings': embeddings}, fOut)\n",
    "    \n",
    "# Specifica il percorso della cartella dove sono presenti le rappresentazioni create tramite modello  \n",
    "file_path = \"/content/drive/My Drive/TMAG_Probing_Cita/Bert_Representations/lenght150/Finetuned/ ItalianUD_Representations150_ft.pkl\"\n",
    "##### VARIAZIONE IN PROBING SU MODELLO PRETRAINED:\n",
    "##### file_path = \"/content/drive/My Drive/TMAG_Probing_Cita/Bert_Representations/lenght150/Pretrained/ ItalianUD_Representations150_pt.pkl\"\n",
    "\n",
    "# Apre il file in modalità lettura \n",
    "with open(file_path, \"rb\") as fIn:\n",
    "# Carica i dati dal file\n",
    "data = pickle.load(fIn)\n",
    "\n",
    "# Definizione delle variabili per accedere ai dati nel dizionario\n",
    "ids = data['ids']\n",
    "sentences = data['sentences']\n",
    "embeddings = data['embeddings']\n",
    "\n",
    "# Caricamento del dataset con le features linguistiche estratte tramite ProfilingUD\n",
    "Features_file = \"/content/drive/My Drive/TMAG_Probing_Cita/dfs_post-cleaning/UD_15000records/Gold_UD.tsv\"\n",
    "# Letture del DataFrame da un file .tsv\n",
    "df = pd.read_csv(Features_file, delimiter='\\t')\n",
    "df = df.set_index(\"ID\")\n",
    "\n",
    "# Salva in una lista i nomi di tutte le features\n",
    "lista_features = df.columns.tolist()\n",
    "\n",
    "# Funzione che data la lista delle features restituisce diverse liste per ogni macro-gruppo di features\n",
    "def create_feature_lists(lista_colonne):\n",
    "    \n",
    "    # Definizione delle liste vuote\n",
    "    raw_text_properties = []\n",
    "    lexical_variety = []\n",
    "    morphosyntactic_info_1 = []\n",
    "    morphosyntactic_info_2_infmorph =[]\n",
    "    verbal_predicate_structure = []\n",
    "    parsed_tree_structures = []\n",
    "    order_of_elements = []\n",
    "    syntactic_relations = []\n",
    "    subordination_features = []\n",
    "    all_features = []\n",
    " \n",
    "    # Inserimento di ogni feature all'interno della lista dedicata\n",
    "    for colonna in lista_colonne:\n",
    "        if 'n_sentences' in colonna or 'n_tokens' in colonna or 'tokens_per_sent' in colonna or 'char_per_tok' in colonna:\n",
    "            raw_text_properties.append(colonna)\n",
    "        elif 'ttr_' in colonna or 'lexical_density' in colonna:\n",
    "            lexical_variety.append(colonna)\n",
    "        elif 'upos_dist_' in colonna or 'lexical_density' in colonna:\n",
    "            morphosyntactic_info_1.append(colonna)\n",
    "        elif 'verbs_tense_dist_' in colonna or 'verbs_mood_dist_' in colonna or 'verbs_form_dist_' in colonna or 'verbs_num_pers_dist_' in colonna:\n",
    "            morphosyntactic_info_2_infmorph.append(colonna)\n",
    "        elif 'verbal_head_per_sent' in colonna or 'verbal_root_perc' in colonna or 'avg_verb_edges' in colonna or 'verb_edges_dist_' in colonna:\n",
    "            verbal_predicate_structure.append(colonna)\n",
    "        elif 'avg_max_depth' in colonna or 'avg_token_per_clause' in colonna or 'avg_links_len' in colonna or 'avg_max_links_len' in colonna or 'max_links_len' in colonna:\n",
    "            parsed_tree_structures.append(colonna)\n",
    "        elif 'obj_pre' in colonna or 'obj_post' in colonna or 'subj_pre' in colonna or 'subj_post' in colonna:\n",
    "            order_of_elements.append(colonna)\n",
    "        elif 'dep_dist_' in colonna:\n",
    "            syntactic_relations.append(colonna)\n",
    "        elif 'principal_proposition_dist' in colonna or 'subordinate_proposition_dist' in colonna or 'subordinate_post' in colonna or 'subordinate_pre' in colonna or 'avg_subordinate_chain_len' in colonna or 'subordinate_dist_' in colonna:\n",
    "            subordination_features.append(colonna)\n",
    "        all_features.append(colonna)\n",
    "    return {\n",
    "        \"Proprietà del Testo Grezzo\": raw_text_properties,\n",
    "        \"Variazione Lessicale\": lexical_variety,\n",
    "        \"Informazioni Morfosintattiche\": morphosyntactic_info_1,\n",
    "        \"Informazioni Morfosintattiche - Morfologia flessiva\": morphosyntactic_info_2_infmorph,\n",
    "        \"Caratteristiche Sintattiche - Struttura del Predicato Verbale\": verbal_predicate_structure,\n",
    "        \"Caratteristiche Sintattiche - Strutture Alberate Analizzate Globalmente e Localmente\": parsed_tree_structures,\n",
    "        \"Caratteristiche Sintattiche - Ordine degli Elementi\": order_of_elements,\n",
    "        \"Caratteristiche Sintattiche - Relazioni Sintattiche\": syntactic_relations,\n",
    "        \"Caratteristiche Sintattiche - Uso della Subordinazione\": subordination_features,\n",
    "        \"Tutte le Features\": all_features\n",
    "    }\n",
    "# Chiama la funzione create_feature_lists sulla lista delle features\n",
    "features_divise = create_feature_lists(lista_features)\n",
    "\n",
    "# Funzione per esecuzione del processo di probing\n",
    "def probing(embeddings, df, ids, feature, layer):\n",
    "\n",
    "    # Dataset contenente solo le feature linguistiche selezionate \n",
    "    df_feature = df[feature]\n",
    "    X = []\n",
    "    y = []\n",
    "    # Itera gli id e gli embeddings\n",
    "    for id, sentence in zip(ids, embeddings):\n",
    "        # Estrae le rappresentazioni dal token [CLS] (primo token in ogni sequenza di input)\n",
    "        cls_embedding = sentence[layer].tolist()\n",
    "        # Accesso al valore della feature linguistica per la data frase basata sull'id \n",
    "        feat = df_feature.loc[id]\n",
    "        X.append(cls_embedding)\n",
    "        y.append(feat)\n",
    "\n",
    "    # Divide il dataset in train e test \n",
    "    X_train, X_test, y_train, y_test, ids_train, ids_test = train_test_split(X, y, ids, test_size=0.20, random_state=42)\n",
    "\n",
    "    # Definizione del probing model\n",
    "    probing_model = LinearSVR(dual=False, loss='squared_epsilon_insensitive')\n",
    "\n",
    "    # Addestramento del modello sul training set e poi effettua predizioni sul test\n",
    "    probing_model.fit(X_train, y_train)\n",
    "    y_pred = probing_model.predict(X_test)\n",
    "\n",
    "    # Valutazione delle predizioni\n",
    "    corr, p_val = spearmanr(y_test, y_pred)\n",
    "\n",
    "    # Salvataggio delle predizioni per ulteriori analisi \n",
    "    df_preds = pd.DataFrame(columns=[\"sent_id\", \"y_true\", \"y_pred\"])\n",
    "    df_preds[\"sent_id\"] = ids_test\n",
    "    df_preds[\"y_true\"] = y_test\n",
    "    df_preds[\"y_pred\"] = y_pred\n",
    "    df_preds.to_csv(f'/content/drive/My Drive/TMAG_Probing_Cita/Results_SVReg_allMod/lenght150/Result_SVReg_Finetuned/ results_<@\\{layer\\}@>_<@\\{feature\\}@>.tsv',\n",
    "                  sep='\\t', index=True)\n",
    "    return corr, p_val\n",
    "\n",
    "# Definizione ed addestramento del modello baseline\n",
    "def baseline(df, feature):\n",
    "    \n",
    "    # Seleziona \"n_tokens\" come X per il modello probe baseline\n",
    "    X = df[\"n_tokens\"].to_numpy()\n",
    "    X = X.reshape(-1, 1)\n",
    "    y = df[feature].to_numpy()\n",
    "    # Divide dataset in train e test \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "    # Definizione modello probe\n",
    "    probing_model = LinearSVR(dual=False, loss='squared_epsilon_insensitive')\n",
    "    # Fit del modello sui dati di addestramento e predizione su quelli di test \n",
    "    probing_model.fit(X_train, y_train)\n",
    "    y_pred = probing_model.predict(X_test)\n",
    "\n",
    "    # Valutazione delle previsioni\n",
    "    corr, p_val = spearmanr(y_test, y_pred)\n",
    "    return corr, p_val\n",
    "\n",
    "\n",
    "# Stampa delle liste generate\n",
    "for categoria, features in features_divise.items():\n",
    "    print(f\"{categoria}:\", features)\n",
    "    \n",
    "# Itera sulle liste generate dalla funzione create_feature_lists\n",
    "for categoria, selected_features in features_divise.items():\n",
    "    \n",
    "    # Lista con gli indici dei tensori dei layer interessati\n",
    "    layers = [1, 12]\n",
    "    results = pd.DataFrame(index=selected_features, columns=layers + [\"Baseline\"])\n",
    "    # Itera sulle feature selezionate\n",
    "    for feature in selected_features:\n",
    "        # Itera sui layer\n",
    "        for layer in layers:\n",
    "            # Chiamata alla funzione di probing\n",
    "            corr, p_val = probing(embeddings, df, ids, feature, layer)\n",
    "            # Salva il punteggio solo se la correlazione è statisticamente significativa (valore p < 0.05)\n",
    "            if p_val < 0.05:\n",
    "                results.loc[feature][layer] = corr\n",
    "\n",
    "        # Modello baseline addestrato a prevedere le features selezionate usando solo \"n_tokens\" come feature di input\n",
    "        corr_baseline, p_val_baseline = baseline(df, feature)\n",
    "        if p_val_baseline < 0.05:\n",
    "            results.loc[feature][\"Baseline\"] = corr_baseline\n",
    "\n",
    "    # Stampa i risultati per la categoria corrente\n",
    "    print(f\"Risultati per la categoria {categoria}:\\n{results}\")\n",
    "\n",
    "    # Formattazione del dataframe per la visualizzazione \n",
    "    results = results[layers]\n",
    "    results = results.T\n",
    "    results[\"Layers\"] = results.index\n",
    "\n",
    "    # Visualizzazione delle performance tramite plot \n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    g = sns.lineplot(data=results.melt([\"Layers\"]), x=\"Layers\", y=\"value\", hue=\"variable\", linewidth=2)\n",
    "    handles, labels = g.get_legend_handles_labels()\n",
    "    g.legend(handles=handles, labels=labels, bbox_to_anchor=(0., 1.02, 1., .102),\n",
    "             loc='lower left', ncol=3, mode=\"expand\")\n",
    "    # Imposta i ticks e le etichette sull'asse x\n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_xticklabels([1, 12])\n",
    "    \n",
    "    # Mostra il grafico\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
