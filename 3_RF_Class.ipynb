{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12976825-4398-4768-961f-7827e062ae4b",
   "metadata": {},
   "source": [
    "# Classificatore Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a50919-1473-41d2-b8b5-d618e9aa5d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numero di fold\n",
    "num_folds = 10\n",
    "\n",
    "# Inizializzazione delle liste per i valori di accuracy, F1 e valori di feature importance\n",
    "accuracy_list = []\n",
    "fold_f1_scores= []\n",
    "all_importances= []\n",
    "\n",
    "# Ciclo sui fold\n",
    "for i in range(num_folds):\n",
    "   \n",
    "    # Lettura dei dati di addestramento di test e training\n",
    "    train_data = pd.read_csv(f\"kfold_Combo_and_Difference/fold_{i}/train.tsv\", sep='\\t')\n",
    "    test_data = pd.read_csv(f\"kfold_Combo_and_Difference/fold_{i}/test.tsv\", sep='\\t')\n",
    "    \n",
    "    # Estrazione delle feature e delle labels per test e training\n",
    "    X_train = train_data.drop(\"Order_Label\", axis=1)\n",
    "    y_train = train_data[\"Order_Label\"]\n",
    "    X_test = test_data.drop(\"Order_Label\", axis=1)\n",
    "    y_test = test_data[\"Order_Label\"]\n",
    "    \n",
    "    # Estrazione nomi simbolici delle feature\n",
    "    features_names = X_train.columns.tolist()\n",
    "    \n",
    "    # Scaling valori con MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    X_train_fold, y_train_fold = X_train_scaled, y_train\n",
    "    X_test_fold, y_test_fold = X_test_scaled, y_test\n",
    "    \n",
    "    # Creazione del classificatore Random Forest\n",
    "    clf = RandomForestClassifier()\n",
    "\n",
    "    # Addestramento del classificatore su dati di training e test del fold corrente\n",
    "    clf.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Testing del classificatore sul test set per il fold corrente\n",
    "    fold_accuracy = clf.score(X_test_fold, y_test_fold)\n",
    "    # Inserimento l'accuracy corrente nella lista delle accuracy\n",
    "    accuracy_list.append(fold_accuracy)\n",
    "    \n",
    "    # Estrazione dei valori di feature importance\n",
    "    fold_importance= clf.feature_importances_ \n",
    "    # Definizione di un dizionario che ha come chiave il nome della feature e come valore il corrispettivo\n",
    "    feature_importances = dict(zip(features_names, fold_importance))\n",
    "    # Inserimento del dizionario nella lista apposita per tutti i folds\n",
    "    all_importances.append(feature_importances)\n",
    "    \n",
    "    # Estrazione predizioni del modello\n",
    "    y_pred = clf.predict(X_test_fold)\n",
    "    \n",
    "    # Estrazione ed inserimento dei valori dell'F1 nella lista apposit\n",
    "    fold_f1_score = f1_score(y_test_fold, y_pred, average='weighted')\n",
    "    fold_f1_scores.append(fold_f1_score)\n",
    "    \n",
    "    print(\"Iterazione\",i)\n",
    "    \n",
    "    print('Classification report:')\n",
    "    # Stampa classification report\n",
    "    print(classification_report(y_test_fold, y_pred))\n",
    "    # Calcolo della media pesata dell'F1 score per ogni classe\n",
    "    test_f1_score = f1_score(y_test_fold, y_pred, average='weighted')\n",
    "    \n",
    "    print('Confusion matrix:')\n",
    "    cm = confusion_matrix(y_test_fold, y_pred)\n",
    "    # Mostra Confusion Matrix del fold\n",
    "    cm_display = ConfusionMatrixDisplay(cm)\n",
    "    cm_display.display_labels = clf.classes_\n",
    "    cm_display.plot(cmap='Blues', values_format='.4g')\n",
    "    plt.title(f\"Confusion Matrix for Fold {i+1}\")\n",
    "    plt.show()\n",
    "    \n",
    "    print('Feature più utili per discriminare le classi')\n",
    "    \n",
    "    # Ordina le feature in base al loro valore e prende le prime 20\n",
    "    sorted_feature_importance = dict(sorted(feature_importances.items(), key=lambda x: x[1], reverse=True)[:20])\n",
    "    keys = list(sorted_feature_importance.keys())\n",
    "    values = list(sorted_feature_importance.values())\n",
    "    # Crea un grafico a barre\n",
    "    plt.bar(keys, values)\n",
    "    # Aggiunge un titolo e le etichette degli assi\n",
    "    plt.title(\"Feature Importance\")\n",
    "    plt.xlabel(\"Feature\")\n",
    "    plt.ylabel(\"Importance\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "    \n",
    "print (\"Risultati medi su tutti i fold\")\n",
    "# Calcolo dell'accuracy e f1 media\n",
    "mean_accuracy = np.mean(accuracy_list)\n",
    "mean_f1_score=np.mean(fold_f1_scores)\n",
    "\n",
    "# Stampa dell'accuracy e f1 media\n",
    "print(f\"Mean Accuracy: {mean_accuracy}\")\n",
    "print(f\"Mean F1: {mean_f1_score}\")  \n",
    "\n",
    "print(\"Feature importance:\")\n",
    "\n",
    "# Dizionario in cui salvare le medie dei valori per ogni chiave\n",
    "averages_dict = {}\n",
    "\n",
    "# Ciclo sui dizionari nella lista dei dizionari per ogni fold\n",
    "for d in all_importances:\n",
    "    # Ciclo sulle chiavi di ogni dizionario\n",
    "    for key in d.keys():\n",
    "        # Se la chiave non è presente nel dizionario delle medie, la aggiunge con valore 0\n",
    "        if key not in averages_dict:\n",
    "            averages_dict[key] = 0\n",
    "        # Aggiorna la somma parziale dei valori per la chiave corrente\n",
    "        averages_dict[key] += d[key]\n",
    "\n",
    "# Divide le somme parziali per il numero di dizionari nella lista per ottenere la media\n",
    "n = len(all_importances)\n",
    "averages_dict = {key: value / n for key, value in averages_dict.items()}\n",
    "\n",
    "sorted_feature_importances = dict(sorted(averages_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "    \n",
    "# Salvo nelle variabili i nomi e i valori delle prime e ultime 15 feature discriminanti per la classificazione\n",
    "top_features = list(sorted_feature_importances.keys())[:15] + list(sorted_feature_importances.keys())[-15:]\n",
    "top_coef_values = list(sorted_feature_importances.values())[:15] + list(sorted_feature_importances.values())[-15:]\n",
    "\n",
    "\n",
    "colors = ['skyblue' for val in top_coef_values]\n",
    "# Plot delle coppie chiave-valore in ordine decrescente\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.bar(top_features, top_coef_values, color=colors, edgecolor='black')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Importanza')\n",
    "plt.xticks(rotation=90, fontsize=10)\n",
    "plt.title('Significatività delle feature per la classificazione')\n",
    "plt.grid(axis='x', alpha=0.4)\n",
    "# Crea una lista di oggetti Patch per la legenda\n",
    "legend_patches = [Patch(facecolor='darkblue', edgecolor='black', label='Significatività minore'), Patch(facecolor='skyblue', edgecolor='black', label='Significatività maggiore')]\n",
    "# Crea la legenda personalizzata\n",
    "plt.legend(handles=legend_patches)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
