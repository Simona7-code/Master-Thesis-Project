{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12976825-4398-4768-961f-7827e062ae4b",
   "metadata": {},
   "source": [
    "# Classificatore Linear Support Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27260c1f-801c-4ba3-874e-e4c87ce8c15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numero di fold\n",
    "num_folds = 10\n",
    "\n",
    "# Inizializzazione delle liste per i valori di accuracy, F1 e coefficienti\n",
    "accuracy_list = []\n",
    "fold_f1_scores=[]\n",
    "coefs_all=[]\n",
    "\n",
    "# Ciclo sui fold\n",
    "for i in range(num_folds):\n",
    "    \n",
    "    # Lettura dei dati di addestramento di test e training\n",
    "    train_data = pd.read_csv(f\"kfold_Combo_and_Difference/fold_{i}/train.tsv\", sep='\\t')\n",
    "    test_data = pd.read_csv(f\"kfold_Combo_and_Difference/fold_{i}/test.tsv\", sep='\\t')\n",
    "    \n",
    "    # Estrazione delle feature e delle labels per test e training\n",
    "    X_train = train_data.drop(\"Order_Label\", axis=1)\n",
    "    y_train = train_data[\"Order_Label\"]\n",
    "    X_test = test_data.drop(\"Order_Label\", axis=1)\n",
    "    y_test = test_data[\"Order_Label\"]\n",
    "    \n",
    "    # Estrazione nomi simbolici delle feature\n",
    "    features_names = X_train.columns.tolist()\n",
    "    \n",
    "    # Scaling valori con MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    X_train_fold, y_train_fold = X_train_scaled, y_train\n",
    "    X_test_fold, y_test_fold = X_test_scaled, y_test\n",
    "    \n",
    "    # Creazione del classificatore lineare Support Vector\n",
    "    clf = LinearSVC(loss='squared_hinge', max_iter=3000)\n",
    "\n",
    "    # Addestramento del classificatore su dati di training e test del fold corrente\n",
    "    clf.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Testing del classificatore sul test set per il fold corrente\n",
    "    fold_accuracy = clf.score(X_test_fold, y_test_fold)\n",
    "    \n",
    "    # Inserisco l'accuracy corrente nella lista delle accuracy \n",
    "    accuracy_list.append(fold_accuracy)\n",
    "    \n",
    "    # Estraggo predizioni del modello\n",
    "    y_pred = clf.predict(X_test_fold)\n",
    "    \n",
    "    # Estraggo ed inserisco i valori dell'f1 nella lista apposita\n",
    "    fold_f1_score = f1_score(y_test_fold, y_pred, average='weighted')\n",
    "    fold_f1_scores.append(fold_f1_score)\n",
    "    \n",
    "    print(\"Iterazione\",i)\n",
    "    \n",
    "    print('Classification report:')\n",
    "    # Stampa classification report\n",
    "    print(classification_report(y_test_fold, y_pred))\n",
    "    # Calcolo della media pesata delle F1 score per ogni classe\n",
    "    test_f1_score = f1_score(y_test_fold, y_pred, average='weighted')\n",
    "    \n",
    "    print('Confusion matrix:')\n",
    "    cm = confusion_matrix(y_test_fold, y_pred)\n",
    "    # Mostra Confusion Matrix del fold\n",
    "    cm_display = ConfusionMatrixDisplay(cm)\n",
    "    cm_display.display_labels = clf.classes_\n",
    "    cm_display.plot(cmap='Blues', values_format='.4g')\n",
    "    plt.title(f\"Confusion Matrix for Fold {i+1}\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Feature importance\n",
    "\n",
    "    # Estrago coefficienti del modello\n",
    "    coefs = clf.coef_ \n",
    "    idx = 0\n",
    "    class_coefs = coefs[idx]\n",
    "    \n",
    "    # Crea un dizionario che associa ciascun nome di feature al suo coefficiente corrispondente\n",
    "    feature_importances = {feature_name: coef for feature_name, coef in zip(features_names, class_coefs)}\n",
    "    \n",
    "    # Aggiunge il dizionario alla lista che contiene i coefficienti per diverse classi o fold\n",
    "    coefs_all.append(feature_importances)\n",
    "    # Ordina le feature in base al loro valore\n",
    "    sorted_feature_importances = dict(sorted(feature_importances.items(), key=lambda item: item[1], reverse=True))\n",
    "    \n",
    "    # Crea grafico con le 15 feature più discriminanti\n",
    "    num_to_plot = 15\n",
    "    print(f'Feature più utili per discriminare le classi')\n",
    "    plt.barh(range(num_to_plot), list(sorted_feature_importances.values())[:num_to_plot], align='center')\n",
    "    plt.yticks(range(num_to_plot), list(sorted_feature_importances.keys())[:num_to_plot])\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()\n",
    "    \n",
    "# Calcolo dell'accuracy e f1 media\n",
    "mean_accuracy = np.mean(accuracy_list)\n",
    "mean_f1_score=np.mean(fold_f1_scores)\n",
    "\n",
    "print(\"Risultati medi su tutti i fold\")\n",
    "# Stampa dell'accuracy e F1 media\n",
    "print(f\"Mean Accuracy: {mean_accuracy}\")\n",
    "print(f\"Mean F1: {mean_f1_score}\")  \n",
    "\n",
    "# Inizio processo di feature importance\n",
    "\n",
    "list_of_dicts = coefs_al\n",
    "# Conterrà liste di valori di ogni fold per ogni feature\n",
    "result_dict = defaultdict(list)\n",
    "# Per ogni dizionario nella lista\n",
    "for d in list_of_dicts:\n",
    "    # Per ogni chiave nel dizionario\n",
    "    for key, value in d.items():\n",
    "        # Aggiunge il valore alla lista corrispondente alla chiave\n",
    "        result_dict[key].append(value)\n",
    "        \n",
    "# Per ogni chiave di result_dict, ovvero per ogni feature\n",
    "for key, value in result_dict.items():\n",
    "    # Calcola la media dei valori\n",
    "    avg_value = sum(value) / len(value)\n",
    "    # Aggiunge la media come valore della rispettiva feature (key) \n",
    "    result_dict[key] = avg_value\n",
    "       \n",
    "result_dict = dict(result_dict)\n",
    "# Ordina le feature in base al loro valore\n",
    "sorted_feature_importances = dict(sorted(result_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "    \n",
    "# Salva nelle variabili i nomi e i valori delle prime e ultime 15 feature \n",
    "top_features = list(sorted_feature_importances.keys())[:15] + list(sorted_feature_importances.keys())[-15:]\n",
    "top_coef_values = list(sorted_feature_importances.values())[:15] + list(sorted_feature_importances.values())[-15:]\n",
    "\n",
    "# Colori delle barre\n",
    "colors = ['darkblue' if val < 0 else 'skyblue' for val in top_coef_values]\n",
    "\n",
    "# Plot delle coppie chiave-valore in ordine decrescente\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.bar(top_features, top_coef_values, color=colors, edgecolor='black')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Importanza')\n",
    "plt.xticks(rotation=90, fontsize=10)\n",
    "plt.title('Significatività delle feature per la classificazione')\n",
    "plt.grid(axis='x', alpha=0.4)\n",
    "# Crea una lista di oggetti Patch per la legenda\n",
    "legend_patches = [Patch(facecolor='darkblue', edgecolor='black', label='Significatività minore'), Patch(facecolor='skyblue', edgecolor='black', label='Significatività maggiore')]\n",
    "# Crea la legenda personalizzata\n",
    "plt.legend(handles=legend_patches)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
