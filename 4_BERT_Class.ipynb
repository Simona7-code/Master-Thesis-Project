{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12976825-4398-4768-961f-7827e062ae4b",
   "metadata": {},
   "source": [
    "# Classificatore BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a50919-1473-41d2-b8b5-d618e9aa5d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lettura dei dataset di training, test e validation\n",
    "train_data= pd.read_csv('/content/drive/My Drive/TMAG_Classification_BERT/CItA4Finetuning/CItA_150/Train_CItA_Finetuning.csv', delimiter=\",\")\n",
    "test_data = pd.read_csv('/content/drive/My Drive/TMAG_Classification_BERT/CItA4Finetuning/CItA_150/Test_CItA_Finetuning.csv', delimiter=\",\")\n",
    "val_data = pd.read_csv('/content/drive/My Drive/TMAG_Classification_BERT/CItA4Finetuning/CItA_150/Val_CItA_Finetuning.csv', delimiter=\",\")\n",
    "\n",
    "# Selezione delle feature d'interesse per ognuno (saggi e label)\n",
    "train_data=train_data[[\"Formatted_Text\",\"Order_Label\"]].reset_index(drop=True)\n",
    "test_data=test_data[[\"Formatted_Text\",\"Order_Label\"]].reset_index(drop=True)\n",
    "val_data=val_data[[\"Formatted_Text\",\"Order_Label\"]].reset_index(drop=True)\n",
    "\n",
    "# Conversione dati in specifico tipo datasets\n",
    "train = datasets.Dataset.from_pandas(pd.DataFrame(data=train_data))\n",
    "test = datasets.Dataset.from_pandas(pd.DataFrame(data=test_data))\n",
    "dev = datasets.Dataset.from_pandas(pd.DataFrame(data=val_data))\n",
    "\n",
    "# Creazione variabile 'model' con il modello da utilizzare\n",
    "model_name= \"dbmdz/bert-base-italian-xxl-uncased\"\n",
    "# Caricamento del modello\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "# Caricamento del tokenizzatore\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "                                                \n",
    "# Funzione che applica la tokenizzazione ai dati di training, dev e test\n",
    "def tokenize(batch):\n",
    "\n",
    "    # Applica tokenizzazione ai testi\n",
    "    # Limite imposto a 512 subwords, di conseguenza se la sequenza è più lunga viene troncata, se invece non arriva a 512 vengono inseriti degli zeri\n",
    "    tokens = tokenizer(batch['Formatted_Text'], padding=True, truncation=True, max_length=512)\n",
    "    # Assegna le label \n",
    "    tokens['label'] = batch[\"Order_Label\"]\n",
    "    return tokens\n",
    "\n",
    "# Tokenizzazione dei set usando tokenizer del modello\n",
    "train= train.map(tokenize, batched=True)\n",
    "dev = dev.map(tokenize, batched=True)\n",
    "test = test.map(tokenize, batched=True)\n",
    "\n",
    "# Format dei set per il modello\n",
    "train.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "dev.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "test.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])    \n",
    "                                                \n",
    "# Definizione degli argomenti per l'addestramento\n",
    "num_epochs = 2\n",
    "training_args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    num_train_epochs=num_epochs,\n",
    "    logging_steps=15,\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.005,\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "                                                \n",
    "# La funzione prende in input le predictions del modello\n",
    "def compute_metrics(eval_pred):\n",
    "    f1_metric = evaluate.load(\"f1\")\n",
    "    predictions, labels = eval_pred\n",
    "    # Applica argmax alle predictions\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    # Calcola e restituisce l'F-Score fra le predictions e le true labels\n",
    "    return f1_metric.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
    "\n",
    "# Definizione del trainer\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=dev,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Adddestramento\n",
    "trainer.train()\n",
    "# Salvataggio del modello al percorso specificato \n",
    "trainer.save_model(\"/content/drive/My Drive/TMAG_Classification_BERT/CItA4Finetuning/Model_ft/lenght150/FTmode_2ep__set3\")\n",
    "                                                \n",
    "# Estrazione cronologia dei log dall'oggetto trainer\n",
    "log_history = trainer.state.log_history\n",
    "\n",
    "# Creazione dataframe per memorizzare le loss di training e validation\n",
    "df = pd.DataFrame(columns=[\"Epoch\", \"Loss\", \"Training/Validation\"])\n",
    "\n",
    "# Itera sulla cronologia dei log\n",
    "for log_data in log_history:\n",
    "    \n",
    "    epoch = int(log_data[\"epoch\"])\n",
    "    # Se è presente una chiave \"loss\" nel log\n",
    "    if \"loss\" in log_data.keys():\n",
    "    loss = log_data[\"loss\"]\n",
    "    # Memorizza la loss di training nel dataframe\n",
    "    df = df.append({\"Epoch\": epoch, \"Loss\": loss, \"Training/Validation\": \"Training\"}, ignore_index=True)\n",
    "\n",
    "    # Se è presente una chiave \"eval_loss\" nel log\n",
    "    if \"eval_loss\" in log_data.keys():\n",
    "    loss = log_data[\"eval_loss\"]\n",
    "    # Memorizza la loss di validation nel dataframe\n",
    "    df = df.append({\"Epoch\": epoch, \"Loss\": loss, \"Training/Validation\": \"Validation\"}, ignore_index=True)\n",
    "\n",
    "# Creazione lineplot della loss\n",
    "sns.lineplot(data=df, x=\"Epoch\", y=\"Loss\", hue=\"Training/Validation\")\n",
    "                                                \n",
    "# Ricava le prediction del modello\n",
    "output_predictions = trainer.predict(test)\n",
    "\n",
    "# Ottienimento delle label reali dal test set\n",
    "y_test = test[\"label\"].tolist()\n",
    "# Ottienimento delle label predette dal modello\n",
    "y_pred = np.argmax(output_predictions.predictions, axis=1)\n",
    "\n",
    "# Calcola il classification report\n",
    "report= classification_report(y_test, y_pred)\n",
    "# Crea una rappresentazione grafica della matrice di confusione\n",
    "cm = ConfusionMatrixDisplay.from_predictions(y_test, y_pred, xticks_rotation='vertical', cmap='Blues')\n",
    "\n",
    "print(\"Classification Report su test set:\")\n",
    "print(report, \"\\n\")\n",
    "print(\"Confusion Matrix su test set:\")\n",
    "print(cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
